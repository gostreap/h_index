{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse et comprehension des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/57/vt366_td3_37y7bqh4rk7nqr0000gn/T/ipykernel_4148/4115901246.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# from preprocess_utils import *\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from read_data import *\n",
    "from utils import *\n",
    "# from preprocess_utils import *\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_full_dataset_with_features(from_scratch=True, vectorize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**distribution des données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,n_train = get_train_data()\n",
    "test,n_test = get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(x=train['hindex'],bins=187);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**exploitation de model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On est sur que le modèle applique softmax sur la représentation du mot. Nous ou choisit donc d'appliquer un autre régresseur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data for multiple regression model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = get_numpy_data(n=174241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm, X_test_norm = normalize(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XG_BOOST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xg = XGBRegressor(learning_rate=0.01, max_depth=5, objective=\"reg:linear\", subsample=0.7, n_estimators=500)\n",
    "model_xg.fit(X_train,y_train)\n",
    "mod_preds = model_xg.predict(X_test)\n",
    "mean_squared_error(y_test,mod_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn = keras.Sequential()\n",
    "model_nn.add(layers.Dense(64, kernel_initializer='uniform', input_shape=(10,)))\n",
    "model_nn.add(layers.Activation('softmax'))\n",
    "\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "\n",
    "model_nn.compile(loss='mse', optimizer=optimizer)\n",
    "\n",
    "model_nn.fit(X_train,y_train, epochs=10, batch_size=5)\n",
    "mod_nn_preds = model_nn.predict(X_test)\n",
    "print(len(mod_nn_preds))\n",
    "mean_squared_error(y_test,mod_nn_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CATBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "model_cat = CatBoostRegressor(verbose=False)\n",
    "model_cat.fit(X_train, y_train)\n",
    "mod_preds = model_cat.predict(X_test)\n",
    "mean_squared_error(y_test,mod_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import cv, Pool\n",
    "params = {\n",
    "    \"loss_function\":\"RMSE\"\n",
    "}\n",
    "cv_dataset = Pool(data=X_train, label=y_train)\n",
    "cv(cv_dataset, params=params, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Light GBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "d_train = lgb.Dataset(X_train, label = y_train)\n",
    "params = {}\n",
    "params['learning_rate'] = 0.33\n",
    "params['num_iterations'] = 100\n",
    "params['boosting_type'] = 'dart'\n",
    "params['objective'] = 'regression'\n",
    "params['metric'] = 'rmse'\n",
    "params['sub_feature'] = 0.6\n",
    "params['num_leaves'] = 50\n",
    "params['min_data'] = 60\n",
    "params['max_depth'] = 35\n",
    "clf = lgb.train(params, d_train, 100)\n",
    "y_pred=clf.predict(X_test)\n",
    "mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**test linear regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "reg = linear_model.TweedieRegressor().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test,reg_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**test svm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model_svm =SVC(kernel='sigmoid', C=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pred = model_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test,svm_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test CNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soumission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from submit import submit\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# from catboost import CatBoostRegressor\n",
    "\n",
    "model_cat = CatBoostRegressor(verbose=False)\n",
    "model_forest = RandomForestRegressor()\n",
    "model_xg = XGBRegressor(learning_rate=0.01, max_depth=5, objective=\"reg:linear\", subsample=0.7, n_estimators=500)\n",
    "\n",
    "submit(model_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "X_train, y_train, X_test, y_test = get_submission_data()\n",
    "X_train, X_test = normalize(X_train, X_test)\n",
    "\n",
    "\n",
    "d_train = lgb.Dataset(X_train, label = y_train)\n",
    "params = {}\n",
    "params['learning_rate'] = 0.10\n",
    "params['num_iterations'] = 500\n",
    "params['boosting_type'] = 'dart'\n",
    "params['objective'] = 'regression'\n",
    "params['metric'] = 'rmse'\n",
    "params['sub_feature'] = 0.6\n",
    "params['num_leaves'] = 50\n",
    "params['min_data'] = 60\n",
    "params['max_depth'] = 35\n",
    "clf = lgb.train(params, d_train, 100)\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "\n",
    "test, _ = get_test_data()\n",
    "test[\"hindex\"] = y_pred\n",
    "submission = test[[\"author\", \"hindex\"]]\n",
    "submission.to_csv(\"../tmp/submission.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f80d8b31525b6ea3adcf22249f5b1a58cdfe6d9f8b553721dcb1dc5ebfc8b9f9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
