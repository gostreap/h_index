{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8547/1550948794.py:6: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  train, test = get_processed_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174241, 1033)\n"
     ]
    }
   ],
   "source": [
    "from preprocess_utils import *\n",
    "\n",
    "large_hindex = 6\n",
    "huge_hindex = 36\n",
    "\n",
    "train, test = get_processed_data()\n",
    "train = select_columns(train)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = train[\"hindex\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small / Large Index Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130680, 41) (43561, 41)\n",
      "(130680, 41)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_split, test_split = train_test_split(train)\n",
    "print(train_split.shape, test_split.shape)\n",
    "\n",
    "train_split.loc[train_split[\"hindex\"] < large_hindex, \"hindex\"] = 0\n",
    "test_split.loc[test_split[\"hindex\"] < large_hindex, \"hindex\"] = 0\n",
    "train_split.loc[train_split[\"hindex\"] >= large_hindex, \"hindex\"] = 1\n",
    "test_split.loc[test_split[\"hindex\"] >= large_hindex, \"hindex\"] = 1\n",
    "\n",
    "print(train_split.shape)\n",
    "\n",
    "X_train = train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_train = train_split[\"hindex\"].to_numpy()\n",
    "X_test = test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_test = test_split[\"hindex\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8727761070682492\n",
      "0.8741941342050304\n",
      "0.8760236578707916\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "model_cat = CatBoostClassifier(verbose=False)\n",
    "model_cat.fit(X_train, y_train)\n",
    "mod_preds = model_cat.predict(X_test)\n",
    "print(classification_report(y_test, mod_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small / Large / Huge Index Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130680, 41) (43561, 41)\n",
      "(130680, 41)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_split, test_split = train_test_split(train)\n",
    "print(train_split.shape, test_split.shape)\n",
    "\n",
    "train_split.loc[train_split[\"hindex\"] < large_hindex, \"hindex\"] = 0\n",
    "test_split.loc[test_split[\"hindex\"] < large_hindex, \"hindex\"] = 0\n",
    "train_split.loc[((train_split[\"hindex\"] >= large_hindex) & (train_split[\"hindex\"] < huge_hindex)), \"hindex\"] = 1\n",
    "test_split.loc[((test_split[\"hindex\"] >= large_hindex)  & (test_split[\"hindex\"] < huge_hindex)), \"hindex\"] = 1\n",
    "train_split.loc[train_split[\"hindex\"] >= huge_hindex, \"hindex\"] = 2\n",
    "test_split.loc[test_split[\"hindex\"] >= huge_hindex, \"hindex\"] = 2\n",
    "\n",
    "print(train_split.shape)\n",
    "\n",
    "X_train = train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_train = train_split[\"hindex\"].to_numpy()\n",
    "X_test = test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_test = test_split[\"hindex\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.87      0.87     21549\n",
      "         1.0       0.81      0.85      0.83     19807\n",
      "         2.0       0.75      0.47      0.58      2205\n",
      "\n",
      "    accuracy                           0.84     43561\n",
      "   macro avg       0.81      0.73      0.76     43561\n",
      "weighted avg       0.84      0.84      0.84     43561\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, classification_report\n",
    "model_cat = CatBoostClassifier(verbose=False)\n",
    "model_cat.fit(X_train, y_train)\n",
    "mod_preds = model_cat.predict(X_test)\n",
    "print(classification_report(y_test, mod_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Prediction MSE on large hindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130680, 1033) (43561, 1033)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mean_squared_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8547/3493014479.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodel_cat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmod_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_cat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Overall MSE:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0my_big_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlarge_hindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mmod_big_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmod_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlarge_hindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean_squared_error' is not defined"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import train_test_split\n",
    "\n",
    "train_split, test_split = train_test_split(train)\n",
    "print(train_split.shape, test_split.shape)\n",
    "\n",
    "X_train = train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_train = train_split[\"hindex\"].to_numpy()\n",
    "X_test = test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_test = test_split[\"hindex\"].to_numpy()\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "model_cat = CatBoostRegressor(verbose=False)\n",
    "model_cat.fit(X_train, y_train)\n",
    "mod_preds = model_cat.predict(X_test)\n",
    "print(\"Overall MSE:\", mean_squared_error(y_test, mod_preds))\n",
    "y_big_test = [y for y in y_test if y >= large_hindex]\n",
    "mod_big_preds = [mod_preds[i] for i in range(len(y_test)) if y_test[i] >= large_hindex]\n",
    "print(\"Big Hindex MSE:\", mean_squared_error(y_big_test, mod_big_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific Prediction MSE on large hindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6469, 11) (2157, 11)\n",
      "Big Hindex MSE: 170.16960484061605\n"
     ]
    }
   ],
   "source": [
    "big_train = train.loc[train[\"hindex\"] >= large_hindex]\n",
    "\n",
    "big_train_split, big_test_split = train_test_split(big_train)\n",
    "print(big_train_split.shape, big_test_split.shape)\n",
    "\n",
    "X_big_train = big_train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_big_train = big_train_split[\"hindex\"].to_numpy()\n",
    "X_big_test = big_test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_big_test = big_test_split[\"hindex\"].to_numpy()\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "model_cat = CatBoostRegressor(verbose=False)\n",
    "model_cat.fit(X_big_train, y_big_train)\n",
    "mod_preds = model_cat.predict(X_big_test)\n",
    "print(\"Big Hindex MSE:\", mean_squared_error(y_big_test, mod_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Prediction MSE on small hindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130680, 11) (43561, 11)\n",
      "Overall MSE: 51.41873596298948\n",
      "Small Hindex MSE: 25.906271543186012\n"
     ]
    }
   ],
   "source": [
    "train_split, test_split = train_test_split(train)\n",
    "print(train_split.shape, test_split.shape)\n",
    "\n",
    "X_train = train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_train = train_split[\"hindex\"].to_numpy()\n",
    "X_test = test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_test = test_split[\"hindex\"].to_numpy()\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "model_cat = CatBoostRegressor(verbose=False)\n",
    "model_cat.fit(X_train, y_train)\n",
    "mod_preds = model_cat.predict(X_test)\n",
    "print(\"Overall MSE:\", mean_squared_error(y_test, mod_preds))\n",
    "y_small_test = [y for y in y_test if y < large_hindex]\n",
    "mod_small_preds = [mod_preds[i] for i in range(len(y_test)) if y_test[i] < large_hindex]\n",
    "print(\"Small Hindex MSE:\", mean_squared_error(y_small_test, mod_small_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific Prediction MSE on small hindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124211, 11) (41404, 11)\n",
      "Small Hindex MSE: 18.99344045082073\n"
     ]
    }
   ],
   "source": [
    "small_train = train.loc[train[\"hindex\"] < large_hindex]\n",
    "\n",
    "small_train_split, small_test_split = train_test_split(small_train)\n",
    "print(small_train_split.shape, small_test_split.shape)\n",
    "\n",
    "X_small_train = small_train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_small_train = small_train_split[\"hindex\"].to_numpy()\n",
    "X_small_test = small_test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_small_test = small_test_split[\"hindex\"].to_numpy()\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "model_cat = CatBoostRegressor(verbose=False)\n",
    "model_cat.fit(X_small_train, y_small_train)\n",
    "mod_preds = model_cat.predict(X_small_test)\n",
    "print(\"Small Hindex MSE:\", mean_squared_error(y_small_test, mod_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Specific prediction and Large Index Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, mean_squared_error\n",
    "\n",
    "large_hindex = 6\n",
    "\n",
    "train_split, test_split = train_test_split(train)\n",
    "train_split_classifier, test_split_classifier = train_split.copy(), test_split.copy()\n",
    "print(train_split.shape, test_split.shape)\n",
    "\n",
    "large_train_split = train_split.loc[train_split[\"hindex\"] >= large_hindex]\n",
    "large_test_split = test_split.loc[test_split[\"hindex\"] >= large_hindex]\n",
    "small_train_split = train_split.loc[train_split[\"hindex\"] < large_hindex]\n",
    "small_test_split = test_split.loc[test_split[\"hindex\"] < large_hindex]\n",
    "\n",
    "train_split_classifier.loc[train_split_classifier[\"hindex\"] < large_hindex, \"hindex\"] = 0\n",
    "train_split_classifier.loc[train_split_classifier[\"hindex\"] >= large_hindex, \"hindex\"] = 1\n",
    "test_split_classifier.loc[test_split_classifier[\"hindex\"] < large_hindex, \"hindex\"] = 0\n",
    "test_split_classifier.loc[test_split_classifier[\"hindex\"] >= large_hindex, \"hindex\"] = 1\n",
    "\n",
    "# Balance small and large data\n",
    "# large_train_split_temp = large_train_split.append(small_train_split.sample(n=int(len(small_train_split) / 2.5), ignore_index=True))\n",
    "# small_train_split = small_train_split.append(large_train_split_temp.sample(n=int(len(large_train_split) / 1.5), ignore_index=True))\n",
    "# large_train_split = large_train_split_temp\n",
    "\n",
    "print(large_train_split.shape, small_train_split.shape)\n",
    "\n",
    "# Data for the classifier\n",
    "X_train_classifier = train_split_classifier.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_train_classifier = train_split_classifier[\"hindex\"].to_numpy()\n",
    "X_test_classifier = test_split_classifier.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_test_classifier = test_split_classifier[\"hindex\"].to_numpy()\n",
    "\n",
    "# Data for large hindex regressor\n",
    "X_large_train = large_train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_large_train = large_train_split[\"hindex\"].to_numpy()\n",
    "X_large_test = large_test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_large_test = large_test_split[\"hindex\"].to_numpy()\n",
    "\n",
    "# Data for small hindex regressor\n",
    "X_small_train = small_train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_small_train = small_train_split[\"hindex\"].to_numpy()\n",
    "X_small_test = small_test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_small_test = small_test_split[\"hindex\"].to_numpy()\n",
    "\n",
    "# Original Data\n",
    "X_train = train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_train = train_split[\"hindex\"].to_numpy()\n",
    "X_test = test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_test = test_split[\"hindex\"].to_numpy()\n",
    "\n",
    "\n",
    "model = CatBoostRegressor(verbose=False)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "print(\"Classical Hindex MSE:\", mean_squared_error(y_test, preds))\n",
    "print(\"Classical Hindex MSE on small:\", mean_squared_error(y_small_test, model.predict(X_small_test)))\n",
    "print(\"Classical Hindex MSE on large:\", mean_squared_error(y_large_test, model.predict(X_large_test)))\n",
    "\n",
    "\n",
    "model_small = CatBoostRegressor(verbose=False)\n",
    "model_small.fit(X_small_train, y_small_train)\n",
    "small_preds = model_small.predict(X_test)\n",
    "print(\"Small Hindex MSE:\", mean_squared_error(y_test, small_preds))\n",
    "print(\"Small Hindex MSE on small:\", mean_squared_error(y_small_test, model_small.predict(X_small_test)))\n",
    "print(\"Small Hindex MSE on large:\", mean_squared_error(y_large_test, model_small.predict(X_large_test)))\n",
    "\n",
    "\n",
    "model_large = CatBoostRegressor(verbose=False)\n",
    "model_large.fit(X_large_train, y_large_train)\n",
    "large_preds = model_large.predict(X_test)\n",
    "print(\"Large Hindex MSE:\", mean_squared_error(y_test, large_preds))\n",
    "print(\"Large Hindex MSE on small:\", mean_squared_error(y_small_test, model_large.predict(X_small_test)))\n",
    "print(\"Large Hindex MSE on large:\", mean_squared_error(y_large_test, model_large.predict(X_large_test)))\n",
    "\n",
    "\n",
    "hindex_classifier = CatBoostClassifier(verbose=False, num_trees=2000)\n",
    "hindex_classifier.fit(X_train_classifier, y_train_classifier)\n",
    "hindex_classifier_preds = hindex_classifier.predict(X_test_classifier)\n",
    "print(accuracy_score(y_test_classifier, hindex_classifier_preds), f1_score(y_test_classifier,hindex_classifier_preds), recall_score(y_test_classifier,hindex_classifier_preds))\n",
    "\n",
    "hindex_classifier_probas = hindex_classifier.predict_proba(X_test_classifier)\n",
    "\n",
    "combine_preds = []\n",
    "count_small, count_large, count_classic = 0, 0, 0\n",
    "count_small_correct, count_large_correct = 0, 0\n",
    "\n",
    "threshold = 0.95\n",
    "for i in range(len(y_test)):\n",
    "    # if hindex_classifier_preds == 0:\n",
    "    #     combine_preds.append(small_preds[i])\n",
    "    # else:\n",
    "    #     combine_preds.append(large_preds[i])\n",
    "    # if hindex_classifier_probas[i][0] > threshold:\n",
    "    #     combine_preds.append(small_preds[i])\n",
    "    #     count_small += 1\n",
    "    #     if y_test_classifier[i] == 0:\n",
    "    #         count_small_correct += 1\n",
    "    # elif hindex_classifier_probas[i][1] > threshold:\n",
    "    #     combine_preds.append(large_preds[i])\n",
    "    #     count_large += 1\n",
    "    #     if y_test_classifier[i] == 1:\n",
    "    #         count_large_correct += 1\n",
    "    # else:\n",
    "    #     combine_preds.append(preds[i])\n",
    "    #     count_classic += 1\n",
    "    combine_preds.append((hindex_classifier_probas[i][0] * small_preds[i] + hindex_classifier_probas[i][1] * large_preds[i] + preds[i]) / 2)\n",
    "\n",
    "print(\"Combine Hindex MSE:\", mean_squared_error(y_test, combine_preds))\n",
    "# print(\"count :\", count_small, count_large, count_classic)\n",
    "# print(\"count correct:\", count_small_correct, count_large_correct)\n",
    "# print(\"ratio correct:\", count_small_correct/count_small, count_large_correct/count_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn.metrics import classification_report, mean_squared_error\n",
    "import math\n",
    "\n",
    "\n",
    "def get_small_data(train, test, large_hindex):\n",
    "    small_train = train.loc[train_split[\"hindex\"] < large_hindex]\n",
    "    small_test = test.loc[test_split[\"hindex\"] < large_hindex]\n",
    "\n",
    "    # Data for small hindex regressor\n",
    "    X_small_train = small_train.drop([\"author\", \"hindex\"], axis=1).to_numpy()\n",
    "    y_small_train = small_train[\"hindex\"].to_numpy()\n",
    "    X_small_test = small_test.drop([\"author\", \"hindex\"], axis=1).to_numpy()\n",
    "    y_small_test = small_test[\"hindex\"].to_numpy()\n",
    "\n",
    "    return X_small_train, y_small_train, X_small_test, y_small_test\n",
    "\n",
    "\n",
    "def get_large_data(train, test, large_hindex, huge_hindex):\n",
    "    large_train = train.loc[\n",
    "        (train_split[\"hindex\"] >= large_hindex) & (train_split[\"hindex\"] < huge_hindex)\n",
    "    ]\n",
    "    large_test = test.loc[\n",
    "        (test_split[\"hindex\"] >= large_hindex) & (test_split[\"hindex\"] < huge_hindex)\n",
    "    ]\n",
    "\n",
    "    # Data for large hindex regressor\n",
    "    X_large_train = large_train.drop([\"author\", \"hindex\"], axis=1).to_numpy()\n",
    "    y_large_train = large_train[\"hindex\"].to_numpy()\n",
    "    X_large_test = large_test.drop([\"author\", \"hindex\"], axis=1).to_numpy()\n",
    "    y_large_test = large_test[\"hindex\"].to_numpy()\n",
    "\n",
    "    return X_large_train, y_large_train, X_large_test, y_large_test\n",
    "\n",
    "\n",
    "def get_huge_data(train, test, huge_hindex):\n",
    "    huge_train = train.loc[train_split[\"hindex\"] >= huge_hindex]\n",
    "    huge_test = test.loc[test_split[\"hindex\"] >= huge_hindex]\n",
    "\n",
    "    # Data for huge hindex regressor\n",
    "    X_huge_train = huge_train.drop([\"author\", \"hindex\"], axis=1).to_numpy()\n",
    "    y_huge_train = huge_train[\"hindex\"].to_numpy()\n",
    "    X_huge_test = huge_test.drop([\"author\", \"hindex\"], axis=1).to_numpy()\n",
    "    y_huge_test = huge_test[\"hindex\"].to_numpy()\n",
    "\n",
    "    return X_huge_train, y_huge_train, X_huge_test, y_huge_test\n",
    "\n",
    "\n",
    "def get_classifier_data(train, test):\n",
    "    train = train.copy()\n",
    "    test = test.copy()\n",
    "    \n",
    "    train.loc[train_split[\"hindex\"] < large_hindex, \"hindex\"] = 0\n",
    "    test.loc[test_split[\"hindex\"] < large_hindex, \"hindex\"] = 0\n",
    "    train.loc[((train_split[\"hindex\"] >= large_hindex) & (train_split[\"hindex\"] < huge_hindex)), \"hindex\"] = 1\n",
    "    test.loc[((test_split[\"hindex\"] >= large_hindex)  & (test_split[\"hindex\"] < huge_hindex)), \"hindex\"] = 1\n",
    "    train.loc[train_split[\"hindex\"] >= huge_hindex, \"hindex\"] = 2\n",
    "    test.loc[test_split[\"hindex\"] >= huge_hindex, \"hindex\"] = 2\n",
    "\n",
    "    # Data for the classifier\n",
    "    X_train_classifier = train_split_classifier.drop(\n",
    "        [\"author\", \"hindex\"], axis=1\n",
    "    ).to_numpy()\n",
    "    y_train_classifier = train_split_classifier[\"hindex\"].to_numpy()\n",
    "    X_test_classifier = test_split_classifier.drop(\n",
    "        [\"author\", \"hindex\"], axis=1\n",
    "    ).to_numpy()\n",
    "    y_test_classifier = test_split_classifier[\"hindex\"].to_numpy()\n",
    "\n",
    "    return X_train_classifier, y_train_classifier, X_test_classifier, y_test_classifier\n",
    "\n",
    "def get_original_data(train, test):\n",
    "    # Original Data\n",
    "    X_train = train_split.drop(\n",
    "        [\"author\", \"hindex\"], axis=1\n",
    "    ).to_numpy()\n",
    "    y_train = train_split[\"hindex\"].to_numpy()\n",
    "    X_test = test_split.drop(\n",
    "        [\"author\", \"hindex\"], axis=1\n",
    "    ).to_numpy()\n",
    "    y_test = test_split[\"hindex\"].to_numpy()\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicate very large hindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130680, 11)\n",
      "Classical Hindex MSE: 51.031006030063494\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, mean_squared_error\n",
    "\n",
    "very_large_hindex = 36\n",
    "\n",
    "train_split, test_split = train_test_split(train)\n",
    "\n",
    "very_large_train_split = train_split.loc[train_split[\"hindex\"] >= very_large_hindex]\n",
    "\n",
    "train_split = train_split.append(very_large_train_split)\n",
    "print(train_split.shape)\n",
    "\n",
    "X_train = train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_train = train_split[\"hindex\"].to_numpy()\n",
    "X_test = test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_test = test_split[\"hindex\"].to_numpy()\n",
    "\n",
    "\n",
    "model = CatBoostRegressor(verbose=False)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "print(\"Classical Hindex MSE:\", mean_squared_error(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fasttext Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6653/626770302.py:5: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  train_fasttext, test_fasttext = get_processed_data()\n",
      "Read 99M words\n",
      "Number of words:  359997\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 5831801 lr:  0.000000 avg.loss:  0.556754 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from preprocess_utils import df_to_txt\n",
    "\n",
    "large_hindex = 6\n",
    "train_fasttext, test_fasttext = get_processed_data()\n",
    "train_fasttext[\"hindex_lab\"] = np.where(train_fasttext[\"hindex\"] >= large_hindex, \"__label__1\", \"__label__0\")\n",
    "\n",
    "train_fasttext_split, test_fasttext_split = train_test_split(train_fasttext)\n",
    "\n",
    "path_fasttext_text = \"../tmp/fasttext_text.txt\"\n",
    "df_to_txt(train_fasttext, path_fasttext_text)\n",
    "model_fasttext = fasttext.train_supervised(\n",
    "        path_fasttext_text, lr=0.15815, dim=2, epoch=33, wordNgrams=3\n",
    ")\n",
    "os.remove(path_fasttext_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43561, 0.7491104428272997, 0.7491104428272997)\n"
     ]
    }
   ],
   "source": [
    "path_fasttext_text = \"../tmp/fasttext_text.txt\"\n",
    "df_to_txt(test_fasttext_split, path_fasttext_text)\n",
    "print(model_fasttext.test(path_fasttext_text))\n",
    "os.remove(path_fasttext_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Fasttext prediction to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2171/1682128439.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fasttext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_fasttext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fasttext/FastText.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, text, k, threshold, on_unicode_error)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_probs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_unicode_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fasttext/FastText.py\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(entry)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m                 raise ValueError(\n\u001b[1;32m    213\u001b[0m                     \u001b[0;34m\"predict processes one line at a time (remove \\'\\\\n\\')\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "preds = model_fasttext.predict(train_fasttext[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>hindex</th>\n",
       "      <th>nb_paper</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>authority</th>\n",
       "      <th>clustering_coef</th>\n",
       "      <th>n_neighbors_dist_1</th>\n",
       "      <th>mean_neighbors_dist_1</th>\n",
       "      <th>max_neighbors_dist_1</th>\n",
       "      <th>vector_coord_0</th>\n",
       "      <th>vector_coord_1</th>\n",
       "      <th>fasttext_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1964267543</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.339138e-13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>39</td>\n",
       "      <td>-0.186604</td>\n",
       "      <td>0.288065</td>\n",
       "      <td>__label__1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2153592714</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.433035e-17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.239073</td>\n",
       "      <td>0.446518</td>\n",
       "      <td>__label__0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>217158525</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.750288e-20</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.225883</td>\n",
       "      <td>0.357737</td>\n",
       "      <td>__label__1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2123103677</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>7.714573e-16</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>7</td>\n",
       "      <td>11.833333</td>\n",
       "      <td>54</td>\n",
       "      <td>-0.174987</td>\n",
       "      <td>0.208499</td>\n",
       "      <td>__label__1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2067710487</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-1.444459e-26</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>9.841160</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.170414</td>\n",
       "      <td>0.257662</td>\n",
       "      <td>__label__1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author  hindex  nb_paper  pagerank     authority  clustering_coef  \\\n",
       "0  1964267543     4.0         5  0.000004  3.339138e-13         1.000000   \n",
       "1  2153592714    13.0         5  0.000002  1.433035e-17         1.000000   \n",
       "2   217158525     8.0         5  0.000003  6.750288e-20         1.000000   \n",
       "3  2123103677    11.0         3  0.000005  7.714573e-16         0.714286   \n",
       "4  2067710487     3.0         2  0.000004 -1.444459e-26         0.000000   \n",
       "\n",
       "   n_neighbors_dist_1  mean_neighbors_dist_1  max_neighbors_dist_1  \\\n",
       "0                   5              21.800000                    39   \n",
       "1                   2              20.000000                    20   \n",
       "2                   2               2.000000                     2   \n",
       "3                   7              11.833333                    54   \n",
       "4                   2               9.841160                    12   \n",
       "\n",
       "   vector_coord_0  vector_coord_1 fasttext_pred  \n",
       "0       -0.186604        0.288065    __label__1  \n",
       "1       -0.239073        0.446518    __label__0  \n",
       "2       -0.225883        0.357737    __label__1  \n",
       "3       -0.174987        0.208499    __label__1  \n",
       "4       -0.170414        0.257662    __label__1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 174241/174241 [00:14<00:00, 11636.55it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "fasttext_pred = []\n",
    "for text in tqdm(train_fasttext[\"text\"].to_list()):\n",
    "    if not pd.isna(text):\n",
    "        label, proba = model_fasttext.predict(text)\n",
    "    else:\n",
    "        label, proba = model_fasttext.predict(\"\")\n",
    "    if label[0] == \"__label__1\":\n",
    "        fasttext_pred.append(proba[0])\n",
    "    else: \n",
    "        fasttext_pred.append(1-proba[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"fasttext_pred\"] = fasttext_pred"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
