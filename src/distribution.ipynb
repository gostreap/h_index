{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess_utils import *\n",
    "\n",
    "large_hindex = 6\n",
    "huge_hindex = 36\n",
    "\n",
    "train, test = get_processed_data()\n",
    "train = select_columns(train)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = train[\"hindex\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small / Large Index Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_split, test_split = train_test_split(train)\n",
    "print(train_split.shape, test_split.shape)\n",
    "\n",
    "train_split.loc[train_split[\"hindex\"] < large_hindex, \"hindex\"] = 0\n",
    "test_split.loc[test_split[\"hindex\"] < large_hindex, \"hindex\"] = 0\n",
    "train_split.loc[train_split[\"hindex\"] >= large_hindex, \"hindex\"] = 1\n",
    "test_split.loc[test_split[\"hindex\"] >= large_hindex, \"hindex\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "model_cat = CatBoostClassifier(verbose=False, text_features=[\"text\"])\n",
    "model_cat.fit(train_split.drop([\"author\", \"hindex\"], axis=1), train_split[\"hindex\"])\n",
    "mod_preds = model_cat.predict(test_split.drop([\"author\", \"hindex\"], axis=1))\n",
    "print(classification_report(test_split[\"hindex\"], mod_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small / Large / Huge Index Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_split, test_split = train_test_split(train)\n",
    "print(train_split.shape, test_split.shape)\n",
    "\n",
    "train_split.loc[train_split[\"hindex\"] < large_hindex, \"hindex\"] = 0\n",
    "test_split.loc[test_split[\"hindex\"] < large_hindex, \"hindex\"] = 0\n",
    "train_split.loc[((train_split[\"hindex\"] >= large_hindex) & (train_split[\"hindex\"] < huge_hindex)), \"hindex\"] = 1\n",
    "test_split.loc[((test_split[\"hindex\"] >= large_hindex)  & (test_split[\"hindex\"] < huge_hindex)), \"hindex\"] = 1\n",
    "train_split.loc[train_split[\"hindex\"] >= huge_hindex, \"hindex\"] = 2\n",
    "test_split.loc[test_split[\"hindex\"] >= huge_hindex, \"hindex\"] = 2\n",
    "\n",
    "print(train_split.shape)\n",
    "\n",
    "X_train = train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_train = train_split[\"hindex\"].to_numpy()\n",
    "X_test = test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_test = test_split[\"hindex\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, classification_report\n",
    "model_cat = CatBoostClassifier(verbose=False)\n",
    "model_cat.fit(X_train, y_train)\n",
    "mod_preds = model_cat.predict(X_test)\n",
    "print(classification_report(y_test, mod_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Prediction MSE on large hindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import train_test_split\n",
    "\n",
    "train_split, test_split = train_test_split(train)\n",
    "print(train_split.shape, test_split.shape)\n",
    "\n",
    "X_train = train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_train = train_split[\"hindex\"].to_numpy()\n",
    "X_test = test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_test = test_split[\"hindex\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "model_cat = CatBoostRegressor(verbose=False)\n",
    "model_cat.fit(X_train, y_train)\n",
    "mod_preds = model_cat.predict(X_test)\n",
    "print(\"Overall MSE:\", mean_squared_error(y_test, mod_preds))\n",
    "y_big_test = [y for y in y_test if y >= large_hindex]\n",
    "mod_big_preds = [mod_preds[i] for i in range(len(y_test)) if y_test[i] >= large_hindex]\n",
    "print(\"Big Hindex MSE:\", mean_squared_error(y_big_test, mod_big_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific Prediction MSE on large hindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_train = train.loc[train[\"hindex\"] >= large_hindex]\n",
    "\n",
    "big_train_split, big_test_split = train_test_split(big_train)\n",
    "print(big_train_split.shape, big_test_split.shape)\n",
    "\n",
    "X_big_train = big_train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_big_train = big_train_split[\"hindex\"].to_numpy()\n",
    "X_big_test = big_test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_big_test = big_test_split[\"hindex\"].to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "model_cat = CatBoostRegressor(verbose=False)\n",
    "model_cat.fit(X_big_train, y_big_train)\n",
    "mod_preds = model_cat.predict(X_big_test)\n",
    "print(\"Big Hindex MSE:\", mean_squared_error(y_big_test, mod_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Prediction MSE on small hindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split, test_split = train_test_split(train)\n",
    "print(train_split.shape, test_split.shape)\n",
    "\n",
    "X_train = train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_train = train_split[\"hindex\"].to_numpy()\n",
    "X_test = test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_test = test_split[\"hindex\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "model_cat = CatBoostRegressor(verbose=False)\n",
    "model_cat.fit(X_train, y_train)\n",
    "mod_preds = model_cat.predict(X_test)\n",
    "print(\"Overall MSE:\", mean_squared_error(y_test, mod_preds))\n",
    "y_small_test = [y for y in y_test if y < large_hindex]\n",
    "mod_small_preds = [mod_preds[i] for i in range(len(y_test)) if y_test[i] < large_hindex]\n",
    "print(\"Small Hindex MSE:\", mean_squared_error(y_small_test, mod_small_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific Prediction MSE on small hindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train = train.loc[train[\"hindex\"] < large_hindex]\n",
    "\n",
    "small_train_split, small_test_split = train_test_split(small_train)\n",
    "print(small_train_split.shape, small_test_split.shape)\n",
    "\n",
    "X_small_train = small_train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_small_train = small_train_split[\"hindex\"].to_numpy()\n",
    "X_small_test = small_test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_small_test = small_test_split[\"hindex\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "model_cat = CatBoostRegressor(verbose=False)\n",
    "model_cat.fit(X_small_train, y_small_train)\n",
    "mod_preds = model_cat.predict(X_small_test)\n",
    "print(\"Small Hindex MSE:\", mean_squared_error(y_small_test, mod_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Specific prediction and Large Index Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess_utils import get_processed_data, select_columns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "large_hindex = 6\n",
    "\n",
    "train, test = get_processed_data()\n",
    "train = select_columns(train)\n",
    "del test\n",
    "\n",
    "train_split, test_split = train_test_split(train)\n",
    "print(train_split.shape, test_split.shape)\n",
    "\n",
    "large_train_split = train_split.loc[train_split[\"hindex\"] >= large_hindex]\n",
    "large_test_split = test_split.loc[test_split[\"hindex\"] >= large_hindex]\n",
    "small_train_split = train_split.loc[train_split[\"hindex\"] < large_hindex]\n",
    "small_test_split = test_split.loc[test_split[\"hindex\"] < large_hindex]\n",
    "\n",
    "y_test = test_split[\"hindex\"].copy()\n",
    "\n",
    "# Balance small and large data\n",
    "# large_train_split_temp = large_train_split.append(small_train_split.sample(n=int(len(small_train_split) / 2.5), ignore_index=True))\n",
    "# small_train_split = small_train_split.append(large_train_split_temp.sample(n=int(len(large_train_split) / 1.5), ignore_index=True))\n",
    "# large_train_split = large_train_split_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, mean_squared_error\n",
    "\n",
    "model = CatBoostRegressor(verbose=False)\n",
    "model.fit(train_split.drop([\"author\", \"hindex\"], axis=1), train_split[\"hindex\"])\n",
    "preds = model.predict(test_split.drop([\"author\",\"hindex\"], axis=1))\n",
    "print(\"Classical Hindex MSE:\", mean_squared_error(test_split[\"hindex\"], preds))\n",
    "print(\"Classical Hindex MSE on small:\", mean_squared_error(small_test_split[\"hindex\"], model.predict(small_test_split.drop([\"author\",\"hindex\"], axis=1))))\n",
    "print(\"Classical Hindex MSE on large:\", mean_squared_error(large_test_split[\"hindex\"], model.predict(large_test_split.drop([\"author\", \"hindex\"], axis=1))))\n",
    "\n",
    "\n",
    "model_small = CatBoostRegressor(verbose=False)\n",
    "model_small.fit(small_train_split.drop([\"author\",\"hindex\"], axis=1), small_train_split[\"hindex\"])\n",
    "small_preds = model_small.predict(test_split.drop([\"author\",\"hindex\"], axis=1))\n",
    "print(\"Small Hindex MSE:\", mean_squared_error(test_split[\"hindex\"], small_preds))\n",
    "print(\"Small Hindex MSE on small:\", mean_squared_error(small_test_split[\"hindex\"], model_small.predict(small_test_split.drop([\"author\",\"hindex\"], axis=1))))\n",
    "print(\"Small Hindex MSE on large:\", mean_squared_error(large_test_split[\"hindex\"], model_small.predict(large_test_split.drop([\"author\", \"hindex\"], axis=1))))\n",
    "\n",
    "\n",
    "model_large = CatBoostRegressor(verbose=False)\n",
    "model_large.fit(large_train_split.drop([\"author\",\"hindex\"], axis=1), large_train_split[\"hindex\"])\n",
    "large_preds = model_large.predict(test_split.drop([\"author\",\"hindex\"], axis=1))\n",
    "print(\"Large Hindex MSE:\", mean_squared_error(test_split[\"hindex\"], large_preds))\n",
    "print(\"Large Hindex MSE on small:\", mean_squared_error(small_test_split[\"hindex\"], model_large.predict(small_test_split.drop([\"author\",\"hindex\"], axis=1))))\n",
    "print(\"Large Hindex MSE on large:\", mean_squared_error(large_test_split[\"hindex\"], model_large.predict(large_test_split.drop([\"author\", \"hindex\"], axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_classifier, test_split_classifier = train_split, test_split\n",
    "train_split_classifier.loc[train_split_classifier[\"hindex\"] < large_hindex, \"hindex\"] = 0\n",
    "train_split_classifier.loc[train_split_classifier[\"hindex\"] >= large_hindex, \"hindex\"] = 1\n",
    "test_split_classifier.loc[test_split_classifier[\"hindex\"] < large_hindex, \"hindex\"] = 0\n",
    "test_split_classifier.loc[test_split_classifier[\"hindex\"] >= large_hindex, \"hindex\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, classification_report\n",
    "hindex_classifier = CatBoostClassifier(verbose=False, num_trees=2000)\n",
    "hindex_classifier.fit(train_split_classifier.drop([\"author\", \"hindex\"], axis=1), train_split_classifier[\"hindex\"])\n",
    "hindex_classifier_preds = hindex_classifier.predict(test_split_classifier.drop([\"author\", \"hindex\"], axis=1))\n",
    "print(classification_report(test_split_classifier[\"hindex\"], hindex_classifier_preds))\n",
    "\n",
    "hindex_classifier_probas = hindex_classifier.predict_proba(test_split_classifier.drop([\"author\", \"hindex\"], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "combine_preds = []\n",
    "count_small, count_large, count_classic = 0, 0, 0\n",
    "count_small_correct, count_large_correct = 0, 0\n",
    "\n",
    "threshold = 0.95\n",
    "for i in tqdm(range(len(y_test))):\n",
    "    # if hindex_classifier_preds[i] == 0:\n",
    "    #     combine_preds.append(small_preds[i])\n",
    "    # else:\n",
    "    #     combine_preds.append(large_preds[i])\n",
    "    # if hindex_classifier_probas[i][0] > threshold:\n",
    "    #     combine_preds.append(small_preds[i])\n",
    "    #     count_small += 1\n",
    "    #     if hindex_classifier_preds[i] == 0:\n",
    "    #         count_small_correct += 1\n",
    "    # elif hindex_classifier_probas[i][1] > threshold:\n",
    "    #     combine_preds.append(large_preds[i])\n",
    "    #     count_large += 1\n",
    "    #     if hindex_classifier_preds[i] == 1:\n",
    "    #         count_large_correct += 1\n",
    "    # else:\n",
    "    #     combine_preds.append(preds[i])\n",
    "    #     count_classic += 1\n",
    "    combine_preds.append((hindex_classifier_probas[i][0] * small_preds[i] + hindex_classifier_probas[i][1] * large_preds[i] + preds[i]) / 2)\n",
    "    # combine_preds.append(preds[i])\n",
    "\n",
    "print(\"Combine Hindex MSE:\", mean_squared_error(y_test, combine_preds))\n",
    "# print(\"count :\", count_small, count_large, count_classic)\n",
    "# print(\"count correct:\", count_small_correct, count_large_correct)\n",
    "# print(\"ratio correct:\", count_small_correct/count_small, count_large_correct/count_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess_utils import get_processed_data, select_columns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "large_hindex = 6\n",
    "\n",
    "train_split, test_split = get_processed_data()\n",
    "train_split = select_columns(train_split)\n",
    "test_split = select_columns(test_split)\n",
    "print(train_split.shape, test_split.shape)\n",
    "\n",
    "large_train_split = train_split.loc[train_split[\"hindex\"] >= large_hindex]\n",
    "large_test_split = test_split.loc[test_split[\"hindex\"] >= large_hindex]\n",
    "small_train_split = train_split.loc[train_split[\"hindex\"] < large_hindex]\n",
    "small_test_split = test_split.loc[test_split[\"hindex\"] < large_hindex]\n",
    "\n",
    "y_test = test_split[\"header\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, _ = get_test_data()\n",
    "test[\"hindex\"] = combine_preds\n",
    "submission = test[[\"author\", \"hindex\"]]\n",
    "submission.to_csv(\"../tmp/submission.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn.metrics import classification_report, mean_squared_error\n",
    "import math\n",
    "\n",
    "\n",
    "def get_small_data(train, test, large_hindex):\n",
    "    small_train = train.loc[train_split[\"hindex\"] < large_hindex]\n",
    "    small_test = test.loc[test_split[\"hindex\"] < large_hindex]\n",
    "\n",
    "    # Data for small hindex regressor\n",
    "    X_small_train = small_train.drop([\"author\", \"hindex\"], axis=1).to_numpy()\n",
    "    y_small_train = small_train[\"hindex\"].to_numpy()\n",
    "    X_small_test = small_test.drop([\"author\", \"hindex\"], axis=1).to_numpy()\n",
    "    y_small_test = small_test[\"hindex\"].to_numpy()\n",
    "\n",
    "    return X_small_train, y_small_train, X_small_test, y_small_test\n",
    "\n",
    "\n",
    "def get_large_data(train, test, large_hindex, huge_hindex):\n",
    "    large_train = train.loc[\n",
    "        (train_split[\"hindex\"] >= large_hindex) & (train_split[\"hindex\"] < huge_hindex)\n",
    "    ]\n",
    "    large_test = test.loc[\n",
    "        (test_split[\"hindex\"] >= large_hindex) & (test_split[\"hindex\"] < huge_hindex)\n",
    "    ]\n",
    "\n",
    "    # Data for large hindex regressor\n",
    "    X_large_train = large_train.drop([\"author\", \"hindex\"], axis=1).to_numpy()\n",
    "    y_large_train = large_train[\"hindex\"].to_numpy()\n",
    "    X_large_test = large_test.drop([\"author\", \"hindex\"], axis=1).to_numpy()\n",
    "    y_large_test = large_test[\"hindex\"].to_numpy()\n",
    "\n",
    "    return X_large_train, y_large_train, X_large_test, y_large_test\n",
    "\n",
    "\n",
    "def get_huge_data(train, test, huge_hindex):\n",
    "    huge_train = train.loc[train_split[\"hindex\"] >= huge_hindex]\n",
    "    huge_test = test.loc[test_split[\"hindex\"] >= huge_hindex]\n",
    "\n",
    "    # Data for huge hindex regressor\n",
    "    X_huge_train = huge_train.drop([\"author\", \"hindex\"], axis=1).to_numpy()\n",
    "    y_huge_train = huge_train[\"hindex\"].to_numpy()\n",
    "    X_huge_test = huge_test.drop([\"author\", \"hindex\"], axis=1).to_numpy()\n",
    "    y_huge_test = huge_test[\"hindex\"].to_numpy()\n",
    "\n",
    "    return X_huge_train, y_huge_train, X_huge_test, y_huge_test\n",
    "\n",
    "\n",
    "def get_classifier_data(train, test):\n",
    "    train = train.copy()\n",
    "    test = test.copy()\n",
    "    \n",
    "    train.loc[train_split[\"hindex\"] < large_hindex, \"hindex\"] = 0\n",
    "    test.loc[test_split[\"hindex\"] < large_hindex, \"hindex\"] = 0\n",
    "    train.loc[((train_split[\"hindex\"] >= large_hindex) & (train_split[\"hindex\"] < huge_hindex)), \"hindex\"] = 1\n",
    "    test.loc[((test_split[\"hindex\"] >= large_hindex)  & (test_split[\"hindex\"] < huge_hindex)), \"hindex\"] = 1\n",
    "    train.loc[train_split[\"hindex\"] >= huge_hindex, \"hindex\"] = 2\n",
    "    test.loc[test_split[\"hindex\"] >= huge_hindex, \"hindex\"] = 2\n",
    "\n",
    "    # Data for the classifier\n",
    "    X_train_classifier = train_split_classifier.drop(\n",
    "        [\"author\", \"hindex\"], axis=1\n",
    "    ).to_numpy()\n",
    "    y_train_classifier = train_split_classifier[\"hindex\"].to_numpy()\n",
    "    X_test_classifier = test_split_classifier.drop(\n",
    "        [\"author\", \"hindex\"], axis=1\n",
    "    ).to_numpy()\n",
    "    y_test_classifier = test_split_classifier[\"hindex\"].to_numpy()\n",
    "\n",
    "    return X_train_classifier, y_train_classifier, X_test_classifier, y_test_classifier\n",
    "\n",
    "def get_original_data(train, test):\n",
    "    # Original Data\n",
    "    X_train = train_split.drop(\n",
    "        [\"author\", \"hindex\"], axis=1\n",
    "    ).to_numpy()\n",
    "    y_train = train_split[\"hindex\"].to_numpy()\n",
    "    X_test = test_split.drop(\n",
    "        [\"author\", \"hindex\"], axis=1\n",
    "    ).to_numpy()\n",
    "    y_test = test_split[\"hindex\"].to_numpy()\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicate very large hindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, mean_squared_error\n",
    "\n",
    "very_large_hindex = 36\n",
    "\n",
    "train_split, test_split = train_test_split(train)\n",
    "\n",
    "very_large_train_split = train_split.loc[train_split[\"hindex\"] >= very_large_hindex]\n",
    "\n",
    "train_split = train_split.append(very_large_train_split)\n",
    "print(train_split.shape)\n",
    "\n",
    "X_train = train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_train = train_split[\"hindex\"].to_numpy()\n",
    "X_test = test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_test = test_split[\"hindex\"].to_numpy()\n",
    "\n",
    "\n",
    "model = CatBoostRegressor(verbose=False)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "print(\"Classical Hindex MSE:\", mean_squared_error(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fasttext Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from preprocess_utils import df_to_txt\n",
    "\n",
    "large_hindex = 6\n",
    "train_fasttext, test_fasttext = get_processed_data()\n",
    "train_fasttext[\"hindex_lab\"] = np.where(train_fasttext[\"hindex\"] >= large_hindex, \"__label__1\", \"__label__0\")\n",
    "\n",
    "train_fasttext_split, test_fasttext_split = train_test_split(train_fasttext)\n",
    "\n",
    "path_fasttext_text = \"../tmp/fasttext_text.txt\"\n",
    "df_to_txt(train_fasttext, path_fasttext_text)\n",
    "model_fasttext = fasttext.train_supervised(\n",
    "        path_fasttext_text, lr=0.15815, dim=2, epoch=33, wordNgrams=3\n",
    ")\n",
    "os.remove(path_fasttext_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_fasttext_text = \"../tmp/fasttext_text.txt\"\n",
    "df_to_txt(test_fasttext_split, path_fasttext_text)\n",
    "print(model_fasttext.test(path_fasttext_text))\n",
    "os.remove(path_fasttext_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Fasttext prediction to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model_fasttext.predict(train_fasttext[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "fasttext_pred = []\n",
    "for text in tqdm(train_fasttext[\"text\"].to_list()):\n",
    "    if not pd.isna(text):\n",
    "        label, proba = model_fasttext.predict(text)\n",
    "    else:\n",
    "        label, proba = model_fasttext.predict(\"\")\n",
    "    if label[0] == \"__label__1\":\n",
    "        fasttext_pred.append(proba[0])\n",
    "    else: \n",
    "        fasttext_pred.append(1-proba[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"fasttext_pred\"] = fasttext_pred"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
