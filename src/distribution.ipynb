{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/57/vt366_td3_37y7bqh4rk7nqr0000gn/T/ipykernel_4045/459611240.py:3: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  train, test = get_processed_data()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>hindex</th>\n",
       "      <th>nb_paper</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>authority</th>\n",
       "      <th>clustering_coef</th>\n",
       "      <th>n_neighbors_dist_1</th>\n",
       "      <th>mean_neighbors_dist_1</th>\n",
       "      <th>max_neighbors_dist_1</th>\n",
       "      <th>vector_coord_0</th>\n",
       "      <th>vector_coord_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1964267543</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.339138e-13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>39</td>\n",
       "      <td>-0.091160</td>\n",
       "      <td>0.305486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2153592714</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.433035e-17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.101177</td>\n",
       "      <td>0.459008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>217158525</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.750287e-20</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.113293</td>\n",
       "      <td>0.376834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2123103677</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>7.714573e-16</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>7</td>\n",
       "      <td>11.833333</td>\n",
       "      <td>54</td>\n",
       "      <td>-0.097152</td>\n",
       "      <td>0.216794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2067710487</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-4.887576e-27</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>9.841160</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.079223</td>\n",
       "      <td>0.282824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author  hindex  nb_paper  pagerank     authority  clustering_coef  \\\n",
       "0  1964267543     4.0         5  0.000004  3.339138e-13         1.000000   \n",
       "1  2153592714    13.0         5  0.000002  1.433035e-17         1.000000   \n",
       "2   217158525     8.0         5  0.000003  6.750287e-20         1.000000   \n",
       "3  2123103677    11.0         3  0.000005  7.714573e-16         0.714286   \n",
       "4  2067710487     3.0         2  0.000004 -4.887576e-27         0.000000   \n",
       "\n",
       "   n_neighbors_dist_1  mean_neighbors_dist_1  max_neighbors_dist_1  \\\n",
       "0                   5              21.800000                    39   \n",
       "1                   2              20.000000                    20   \n",
       "2                   2               2.000000                     2   \n",
       "3                   7              11.833333                    54   \n",
       "4                   2               9.841160                    12   \n",
       "\n",
       "   vector_coord_0  vector_coord_1  \n",
       "0       -0.091160        0.305486  \n",
       "1       -0.101177        0.459008  \n",
       "2       -0.113293        0.376834  \n",
       "3       -0.097152        0.216794  \n",
       "4       -0.079223        0.282824  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from preprocess_utils import *\n",
    "\n",
    "train, test = get_processed_data()\n",
    "train = select_columns(train)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.0\n"
     ]
    }
   ],
   "source": [
    "frequency = train[\"hindex\"].value_counts(normalize=True)\n",
    "\n",
    "total = 0\n",
    "for hindex, freq in frequency.items():\n",
    "    total += freq\n",
    "    if total > 0.95:\n",
    "        print(hindex+1)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_hindex = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Index Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130680, 11) (43561, 11)\n",
      "(130680, 11)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_split, test_split = train_test_split(train)\n",
    "print(train_split.shape, test_split.shape)\n",
    "\n",
    "train_split.loc[train_split[\"hindex\"] < large_hindex, \"hindex\"] = 0\n",
    "test_split.loc[test_split[\"hindex\"] < large_hindex, \"hindex\"] = 0\n",
    "train_split.loc[train_split[\"hindex\"] >= large_hindex, \"hindex\"] = 1\n",
    "test_split.loc[test_split[\"hindex\"] >= large_hindex, \"hindex\"] = 1\n",
    "\n",
    "print(train_split.shape)\n",
    "\n",
    "X_train = train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_train = train_split[\"hindex\"].to_numpy()\n",
    "X_test = test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_test = test_split[\"hindex\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8589104933311907\n",
      "0.878137764206686\n",
      "0.8841684967059293\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "model_svm = RandomForestClassifier()\n",
    "model_svm.fit(X_train, y_train)\n",
    "mod_preds = model_svm.predict(X_test)\n",
    "print(accuracy_score(y_test,mod_preds))\n",
    "print(f1_score(y_test,mod_preds))\n",
    "print(recall_score(y_test,mod_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/57/vt366_td3_37y7bqh4rk7nqr0000gn/T/ipykernel_4045/723544597.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_cat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "model_cat = CatBoostClassifier(verbose=False)\n",
    "model_cat.fit(X_train, y_train)\n",
    "mod_preds = model_cat.predict(X_test)\n",
    "print(accuracy_score(y_test,mod_preds))\n",
    "print(f1_score(y_test,mod_preds))\n",
    "print(recall_score(y_test,mod_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Prediction MSE on large hindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split, test_split = train_test_split(train)\n",
    "print(train_split.shape, test_split.shape)\n",
    "\n",
    "X_train = train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_train = train_split[\"hindex\"].to_numpy()\n",
    "X_test = test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_test = test_split[\"hindex\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "model_cat = CatBoostRegressor(verbose=False)\n",
    "model_cat.fit(X_train, y_train)\n",
    "mod_preds = model_cat.predict(X_test)\n",
    "print(\"Overall MSE:\", mean_squared_error(y_test, mod_preds))\n",
    "y_big_test = [y for y in y_test if y >= large_hindex]\n",
    "mod_big_preds = [mod_preds[i] for i in range(len(y_test)) if y_test[i] >= large_hindex]\n",
    "print(\"Big Hindex MSE:\", mean_squared_error(y_big_test, mod_big_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific Prediction MSE on large hindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_train = train.loc[train[\"hindex\"] >= large_hindex]\n",
    "\n",
    "big_train_split, big_test_split = train_test_split(big_train)\n",
    "print(big_train_split.shape, big_test_split.shape)\n",
    "\n",
    "X_big_train = big_train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_big_train = big_train_split[\"hindex\"].to_numpy()\n",
    "X_big_test = big_test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_big_test = big_test_split[\"hindex\"].to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "model_cat = CatBoostRegressor(verbose=False)\n",
    "model_cat.fit(X_big_train, y_big_train)\n",
    "mod_preds = model_cat.predict(X_big_test)\n",
    "print(\"Big Hindex MSE:\", mean_squared_error(y_big_test, mod_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Prediction MSE on small hindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split, test_split = train_test_split(train)\n",
    "print(train_split.shape, test_split.shape)\n",
    "\n",
    "X_train = train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_train = train_split[\"hindex\"].to_numpy()\n",
    "X_test = test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_test = test_split[\"hindex\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "model_cat = CatBoostRegressor(verbose=False)\n",
    "model_cat.fit(X_train, y_train)\n",
    "mod_preds = model_cat.predict(X_test)\n",
    "print(\"Overall MSE:\", mean_squared_error(y_test, mod_preds))\n",
    "y_small_test = [y for y in y_test if y < large_hindex]\n",
    "mod_small_preds = [mod_preds[i] for i in range(len(y_test)) if y_test[i] < large_hindex]\n",
    "print(\"Small Hindex MSE:\", mean_squared_error(y_small_test, mod_small_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific Prediction MSE on small hindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train = train.loc[train[\"hindex\"] < large_hindex]\n",
    "\n",
    "small_train_split, small_test_split = train_test_split(small_train)\n",
    "print(small_train_split.shape, small_test_split.shape)\n",
    "\n",
    "X_small_train = small_train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_small_train = small_train_split[\"hindex\"].to_numpy()\n",
    "X_small_test = small_test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_small_test = small_test_split[\"hindex\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "model_cat = CatBoostRegressor(verbose=False)\n",
    "model_cat.fit(X_small_train, y_small_train)\n",
    "mod_preds = model_cat.predict(X_small_test)\n",
    "print(\"Small Hindex MSE:\", mean_squared_error(y_small_test, mod_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Specific prediction and Large Index Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "\n",
    "large_hindex = 6\n",
    "\n",
    "train_split, test_split = train_test_split(train)\n",
    "train_split_classifier, test_split_classifier = train_split.copy(), test_split.copy()\n",
    "print(train_split.shape, test_split.shape)\n",
    "\n",
    "large_train_split = train_split.loc[train_split[\"hindex\"] >= large_hindex]\n",
    "large_test_split = test_split.loc[test_split[\"hindex\"] >= large_hindex]\n",
    "small_train_split = train_split.loc[train_split[\"hindex\"] < large_hindex]\n",
    "small_test_split = test_split.loc[test_split[\"hindex\"] < large_hindex]\n",
    "\n",
    "train_split_classifier.loc[train_split_classifier[\"hindex\"] < large_hindex, \"hindex\"] = 0\n",
    "train_split_classifier.loc[train_split_classifier[\"hindex\"] >= large_hindex, \"hindex\"] = 1\n",
    "test_split_classifier.loc[test_split_classifier[\"hindex\"] < large_hindex, \"hindex\"] = 0\n",
    "test_split_classifier.loc[test_split_classifier[\"hindex\"] >= large_hindex, \"hindex\"] = 1\n",
    "\n",
    "# Balance small and large data\n",
    "# large_train_split_temp = large_train_split.append(small_train_split.sample(n=int(len(small_train_split) / 3), ignore_index=True))\n",
    "# small_train_split = small_train_split.append(large_train_split_temp.sample(n=int(len(large_train_split) / 1.3), ignore_index=True))\n",
    "# large_train_split = large_train_split_temp\n",
    "\n",
    "print(large_train_split.shape, small_train_split.shape)\n",
    "\n",
    "# Data for the classifier\n",
    "X_train_classifier = train_split_classifier.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_train_classifier = train_split_classifier[\"hindex\"].to_numpy()\n",
    "X_test_classifier = test_split_classifier.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_test_classifier = test_split_classifier[\"hindex\"].to_numpy()\n",
    "\n",
    "# Data for large hindex regressor\n",
    "X_large_train = large_train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_large_train = large_train_split[\"hindex\"].to_numpy()\n",
    "X_large_test = large_test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_large_test = large_test_split[\"hindex\"].to_numpy()\n",
    "\n",
    "# Data for small hindex regressor\n",
    "X_small_train = small_train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_small_train = small_train_split[\"hindex\"].to_numpy()\n",
    "X_small_test = small_test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_small_test = small_test_split[\"hindex\"].to_numpy()\n",
    "\n",
    "# Original Data\n",
    "X_train = train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_train = train_split[\"hindex\"].to_numpy()\n",
    "X_test = test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_test = test_split[\"hindex\"].to_numpy()\n",
    "\n",
    "\n",
    "model = CatBoostRegressor(verbose=False)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "print(\"Classical Hindex MSE:\", mean_squared_error(y_test, preds))\n",
    "print(\"Classical Hindex MSE on small:\", mean_squared_error(y_small_test, model.predict(X_small_test)))\n",
    "print(\"Classical Hindex MSE on large:\", mean_squared_error(y_large_test, model.predict(X_large_test)))\n",
    "\n",
    "\n",
    "model_small = CatBoostRegressor(verbose=False)\n",
    "model_small.fit(X_small_train, y_small_train)\n",
    "small_preds = model_small.predict(X_test)\n",
    "print(\"Small Hindex MSE:\", mean_squared_error(y_test, small_preds))\n",
    "print(\"Small Hindex MSE on small:\", mean_squared_error(y_small_test, model_small.predict(X_small_test)))\n",
    "print(\"Small Hindex MSE on large:\", mean_squared_error(y_large_test, model_small.predict(X_large_test)))\n",
    "\n",
    "\n",
    "model_large = CatBoostRegressor(verbose=False)\n",
    "model_large.fit(X_large_train, y_large_train)\n",
    "large_preds = model_large.predict(X_test)\n",
    "print(\"Large Hindex MSE:\", mean_squared_error(y_test, large_preds))\n",
    "print(\"Large Hindex MSE on small:\", mean_squared_error(y_small_test, model_large.predict(X_small_test)))\n",
    "print(\"Large Hindex MSE on large:\", mean_squared_error(y_large_test, model_large.predict(X_large_test)))\n",
    "\n",
    "\n",
    "hindex_classifier = CatBoostClassifier(verbose=False, num_trees=2000)\n",
    "hindex_classifier.fit(X_train_classifier, y_train_classifier)\n",
    "hindex_classifier_preds = hindex_classifier.predict(X_test_classifier)\n",
    "print(accuracy_score(y_test_classifier, hindex_classifier_preds), f1_score(y_test_classifier,hindex_classifier_preds), recall_score(y_test_classifier,hindex_classifier_preds))\n",
    "\n",
    "combine_preds = []\n",
    "for i in range(len(y_test)):\n",
    "    if hindex_classifier_preds[i] == 0:\n",
    "        combine_preds.append(small_preds[i])\n",
    "    else:\n",
    "        combine_preds.append(large_preds[i])\n",
    "print(\"Combine Hindex MSE:\", mean_squared_error(y_test, combine_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
