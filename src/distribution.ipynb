{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7067/459611240.py:3: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  train, test = get_processed_data()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>hindex</th>\n",
       "      <th>nb_paper</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>authority</th>\n",
       "      <th>clustering_coef</th>\n",
       "      <th>n_neighbors_dist_1</th>\n",
       "      <th>mean_neighbors_dist_1</th>\n",
       "      <th>max_neighbors_dist_1</th>\n",
       "      <th>vector_coord_0</th>\n",
       "      <th>vector_coord_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1964267543</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.339138e-13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>39</td>\n",
       "      <td>-0.186604</td>\n",
       "      <td>0.288065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2153592714</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.433035e-17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.239073</td>\n",
       "      <td>0.446518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>217158525</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>6.750288e-20</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.225883</td>\n",
       "      <td>0.357737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2123103677</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>7.714573e-16</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>7</td>\n",
       "      <td>11.833333</td>\n",
       "      <td>54</td>\n",
       "      <td>-0.174987</td>\n",
       "      <td>0.208499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2067710487</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-1.444459e-26</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>9.841160</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.170414</td>\n",
       "      <td>0.257662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author  hindex  nb_paper  pagerank     authority  clustering_coef  \\\n",
       "0  1964267543     4.0         5  0.000004  3.339138e-13         1.000000   \n",
       "1  2153592714    13.0         5  0.000002  1.433035e-17         1.000000   \n",
       "2   217158525     8.0         5  0.000003  6.750288e-20         1.000000   \n",
       "3  2123103677    11.0         3  0.000005  7.714573e-16         0.714286   \n",
       "4  2067710487     3.0         2  0.000004 -1.444459e-26         0.000000   \n",
       "\n",
       "   n_neighbors_dist_1  mean_neighbors_dist_1  max_neighbors_dist_1  \\\n",
       "0                   5              21.800000                    39   \n",
       "1                   2              20.000000                    20   \n",
       "2                   2               2.000000                     2   \n",
       "3                   7              11.833333                    54   \n",
       "4                   2               9.841160                    12   \n",
       "\n",
       "   vector_coord_0  vector_coord_1  \n",
       "0       -0.186604        0.288065  \n",
       "1       -0.239073        0.446518  \n",
       "2       -0.225883        0.357737  \n",
       "3       -0.174987        0.208499  \n",
       "4       -0.170414        0.257662  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from preprocess_utils import *\n",
    "\n",
    "train, test = get_processed_data()\n",
    "train = select_columns(train)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = train[\"hindex\"].value_counts(normalize=True)\n",
    "\n",
    "total = 0\n",
    "for hindex, freq in frequency.items():\n",
    "    total += freq\n",
    "    if total > 0.95:\n",
    "        print(hindex+1)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_hindex = 36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Index Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130680, 11) (43561, 11)\n",
      "(130680, 11)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_split, test_split = train_test_split(train)\n",
    "print(train_split.shape, test_split.shape)\n",
    "\n",
    "train_split.loc[train_split[\"hindex\"] < large_hindex, \"hindex\"] = 0\n",
    "test_split.loc[test_split[\"hindex\"] < large_hindex, \"hindex\"] = 0\n",
    "train_split.loc[train_split[\"hindex\"] >= large_hindex, \"hindex\"] = 1\n",
    "test_split.loc[test_split[\"hindex\"] >= large_hindex, \"hindex\"] = 1\n",
    "\n",
    "print(train_split.shape)\n",
    "\n",
    "X_train = train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_train = train_split[\"hindex\"].to_numpy()\n",
    "X_test = test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_test = test_split[\"hindex\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9655655287986961\n",
      "0.5639534883720931\n",
      "0.44824399260628467\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "model_cat = CatBoostClassifier(verbose=False)\n",
    "model_cat.fit(X_train, y_train)\n",
    "mod_preds = model_cat.predict(X_test)\n",
    "print(accuracy_score(y_test,mod_preds))\n",
    "print(f1_score(y_test,mod_preds))\n",
    "print(recall_score(y_test,mod_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Prediction MSE on large hindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130680, 11) (43561, 11)\n",
      "Overall MSE: 48.50047673031719\n",
      "Big Hindex MSE: 497.0707295639768\n"
     ]
    }
   ],
   "source": [
    "train_split, test_split = train_test_split(train)\n",
    "print(train_split.shape, test_split.shape)\n",
    "\n",
    "X_train = train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_train = train_split[\"hindex\"].to_numpy()\n",
    "X_test = test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_test = test_split[\"hindex\"].to_numpy()\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "model_cat = CatBoostRegressor(verbose=False)\n",
    "model_cat.fit(X_train, y_train)\n",
    "mod_preds = model_cat.predict(X_test)\n",
    "print(\"Overall MSE:\", mean_squared_error(y_test, mod_preds))\n",
    "y_big_test = [y for y in y_test if y >= large_hindex]\n",
    "mod_big_preds = [mod_preds[i] for i in range(len(y_test)) if y_test[i] >= large_hindex]\n",
    "print(\"Big Hindex MSE:\", mean_squared_error(y_big_test, mod_big_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific Prediction MSE on large hindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6469, 11) (2157, 11)\n",
      "Big Hindex MSE: 170.16960484061605\n"
     ]
    }
   ],
   "source": [
    "big_train = train.loc[train[\"hindex\"] >= large_hindex]\n",
    "\n",
    "big_train_split, big_test_split = train_test_split(big_train)\n",
    "print(big_train_split.shape, big_test_split.shape)\n",
    "\n",
    "X_big_train = big_train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_big_train = big_train_split[\"hindex\"].to_numpy()\n",
    "X_big_test = big_test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_big_test = big_test_split[\"hindex\"].to_numpy()\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "model_cat = CatBoostRegressor(verbose=False)\n",
    "model_cat.fit(X_big_train, y_big_train)\n",
    "mod_preds = model_cat.predict(X_big_test)\n",
    "print(\"Big Hindex MSE:\", mean_squared_error(y_big_test, mod_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Prediction MSE on small hindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130680, 11) (43561, 11)\n",
      "Overall MSE: 51.41873596298948\n",
      "Small Hindex MSE: 25.906271543186012\n"
     ]
    }
   ],
   "source": [
    "train_split, test_split = train_test_split(train)\n",
    "print(train_split.shape, test_split.shape)\n",
    "\n",
    "X_train = train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_train = train_split[\"hindex\"].to_numpy()\n",
    "X_test = test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_test = test_split[\"hindex\"].to_numpy()\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "model_cat = CatBoostRegressor(verbose=False)\n",
    "model_cat.fit(X_train, y_train)\n",
    "mod_preds = model_cat.predict(X_test)\n",
    "print(\"Overall MSE:\", mean_squared_error(y_test, mod_preds))\n",
    "y_small_test = [y for y in y_test if y < large_hindex]\n",
    "mod_small_preds = [mod_preds[i] for i in range(len(y_test)) if y_test[i] < large_hindex]\n",
    "print(\"Small Hindex MSE:\", mean_squared_error(y_small_test, mod_small_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific Prediction MSE on small hindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124211, 11) (41404, 11)\n",
      "Small Hindex MSE: 18.99344045082073\n"
     ]
    }
   ],
   "source": [
    "small_train = train.loc[train[\"hindex\"] < large_hindex]\n",
    "\n",
    "small_train_split, small_test_split = train_test_split(small_train)\n",
    "print(small_train_split.shape, small_test_split.shape)\n",
    "\n",
    "X_small_train = small_train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_small_train = small_train_split[\"hindex\"].to_numpy()\n",
    "X_small_test = small_test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_small_test = small_test_split[\"hindex\"].to_numpy()\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "model_cat = CatBoostRegressor(verbose=False)\n",
    "model_cat.fit(X_small_train, y_small_train)\n",
    "mod_preds = model_cat.predict(X_small_test)\n",
    "print(\"Small Hindex MSE:\", mean_squared_error(y_small_test, mod_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Specific prediction and Large Index Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130680, 11) (43561, 11)\n",
      "(66184, 11) (64496, 11)\n",
      "Classical Hindex MSE: 48.63500832797908\n",
      "Classical Small Hindex MSE: 10.36615628435076\n",
      "Classical Large Hindex MSE: 86.82136926694538\n",
      "Small Hindex MSE: 188.14152413363985\n",
      "Small Hindex MSE on small: 0.8738218202998101\n",
      "Small Hindex MSE on large: 375.005558220566\n",
      "Large Hindex MSE: 72.11524054180073\n",
      "Large Hindex MSE on small: 61.47580263670916\n",
      "Large Hindex MSE on large: 82.73174441728581\n",
      "0.8657973875714515 0.8665662375604857 0.8706200697119795\n",
      "Combine Hindex MSE: 51.477366180864685\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "\n",
    "large_hindex = 6\n",
    "\n",
    "train_split, test_split = train_test_split(train)\n",
    "train_split_classifier, test_split_classifier = train_split.copy(), test_split.copy()\n",
    "print(train_split.shape, test_split.shape)\n",
    "\n",
    "large_train_split = train_split.loc[train_split[\"hindex\"] >= large_hindex]\n",
    "large_test_split = test_split.loc[test_split[\"hindex\"] >= large_hindex]\n",
    "small_train_split = train_split.loc[train_split[\"hindex\"] < large_hindex]\n",
    "small_test_split = test_split.loc[test_split[\"hindex\"] < large_hindex]\n",
    "\n",
    "train_split_classifier.loc[train_split_classifier[\"hindex\"] < large_hindex, \"hindex\"] = 0\n",
    "train_split_classifier.loc[train_split_classifier[\"hindex\"] >= large_hindex, \"hindex\"] = 1\n",
    "test_split_classifier.loc[test_split_classifier[\"hindex\"] < large_hindex, \"hindex\"] = 0\n",
    "test_split_classifier.loc[test_split_classifier[\"hindex\"] >= large_hindex, \"hindex\"] = 1\n",
    "\n",
    "# Balance small and large data\n",
    "# large_train_split_temp = large_train_split.append(small_train_split.sample(n=int(len(small_train_split) / 3), ignore_index=True))\n",
    "# small_train_split = small_train_split.append(large_train_split_temp.sample(n=int(len(large_train_split) / 1.3), ignore_index=True))\n",
    "# large_train_split = large_train_split_temp\n",
    "\n",
    "print(large_train_split.shape, small_train_split.shape)\n",
    "\n",
    "# Data for the classifier\n",
    "X_train_classifier = train_split_classifier.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_train_classifier = train_split_classifier[\"hindex\"].to_numpy()\n",
    "X_test_classifier = test_split_classifier.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_test_classifier = test_split_classifier[\"hindex\"].to_numpy()\n",
    "\n",
    "# Data for large hindex regressor\n",
    "X_large_train = large_train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_large_train = large_train_split[\"hindex\"].to_numpy()\n",
    "X_large_test = large_test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_large_test = large_test_split[\"hindex\"].to_numpy()\n",
    "\n",
    "# Data for small hindex regressor\n",
    "X_small_train = small_train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_small_train = small_train_split[\"hindex\"].to_numpy()\n",
    "X_small_test = small_test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_small_test = small_test_split[\"hindex\"].to_numpy()\n",
    "\n",
    "# Original Data\n",
    "X_train = train_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_train = train_split[\"hindex\"].to_numpy()\n",
    "X_test = test_split.drop(\n",
    "    [\"author\", \"hindex\"], axis=1\n",
    ").to_numpy()\n",
    "y_test = test_split[\"hindex\"].to_numpy()\n",
    "\n",
    "\n",
    "model = CatBoostRegressor(verbose=False)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "print(\"Classical Hindex MSE:\", mean_squared_error(y_test, preds))\n",
    "print(\"Classical Hindex MSE on small:\", mean_squared_error(y_small_test, model.predict(X_small_test)))\n",
    "print(\"Classical Hindex MSE on large:\", mean_squared_error(y_large_test, model.predict(X_large_test)))\n",
    "\n",
    "\n",
    "model_small = CatBoostRegressor(verbose=False)\n",
    "model_small.fit(X_small_train, y_small_train)\n",
    "small_preds = model_small.predict(X_test)\n",
    "print(\"Small Hindex MSE:\", mean_squared_error(y_test, small_preds))\n",
    "print(\"Small Hindex MSE on small:\", mean_squared_error(y_small_test, model_small.predict(X_small_test)))\n",
    "print(\"Small Hindex MSE on large:\", mean_squared_error(y_large_test, model_small.predict(X_large_test)))\n",
    "\n",
    "\n",
    "model_large = CatBoostRegressor(verbose=False)\n",
    "model_large.fit(X_large_train, y_large_train)\n",
    "large_preds = model_large.predict(X_test)\n",
    "print(\"Large Hindex MSE:\", mean_squared_error(y_test, large_preds))\n",
    "print(\"Large Hindex MSE on small:\", mean_squared_error(y_small_test, model_large.predict(X_small_test)))\n",
    "print(\"Large Hindex MSE on large:\", mean_squared_error(y_large_test, model_large.predict(X_large_test)))\n",
    "\n",
    "\n",
    "hindex_classifier = CatBoostClassifier(verbose=False, num_trees=2000)\n",
    "hindex_classifier.fit(X_train_classifier, y_train_classifier)\n",
    "hindex_classifier_preds = hindex_classifier.predict(X_test_classifier)\n",
    "print(accuracy_score(y_test_classifier, hindex_classifier_preds), f1_score(y_test_classifier,hindex_classifier_preds), recall_score(y_test_classifier,hindex_classifier_preds))\n",
    "\n",
    "combine_preds = []\n",
    "for i in range(len(y_test)):\n",
    "    if hindex_classifier_preds[i] == 0:\n",
    "        combine_preds.append(small_preds[i])\n",
    "    else:\n",
    "        combine_preds.append(large_preds[i])\n",
    "print(\"Combine Hindex MSE:\", mean_squared_error(y_test, combine_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
