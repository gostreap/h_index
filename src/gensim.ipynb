{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import read_data\n",
    "from pprint import pprint  # pretty-printer\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/57/vt366_td3_37y7bqh4rk7nqr0000gn/T/ipykernel_1017/762429881.py:2: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  docs = get_processed_data(split=False)[\"text\"].to_list()\n",
      "100%|██████████| 217801/217801 [00:00<00:00, 1492963.73it/s]\n",
      "100%|██████████| 217801/217801 [00:20<00:00, 10662.39it/s]\n",
      "100%|██████████| 217801/217801 [00:12<00:00, 17106.68it/s]\n",
      "100%|██████████| 217801/217801 [00:07<00:00, 30862.86it/s]\n",
      "100%|██████████| 217801/217801 [00:10<00:00, 21392.09it/s]\n"
     ]
    }
   ],
   "source": [
    "from preprocess_utils import get_processed_data\n",
    "docs = get_processed_data(split=False)[\"text\"].to_list()\n",
    "\n",
    "# Tokenize the documents.\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from gensim import corpora\n",
    "\n",
    "# Split the documents into tokens.\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "docs = [doc if not pd.isnull(doc) else \"\" for doc in tqdm(docs) ]\n",
    "for idx in tqdm(range(len(docs))):\n",
    "    # print(docs[idx])\n",
    "    if not pd.isnull(docs[idx]): \n",
    "        docs[idx] = docs[idx].lower()  # Convert to lowercase.\n",
    "        docs[idx] = tokenizer.tokenize(docs[idx])  # Split into words.\n",
    "\n",
    "# Remove numbers, but not words that contain numbers.\n",
    "docs = [[token for token in doc if not token.isnumeric()] for doc in tqdm(docs)]\n",
    "\n",
    "# Remove words that are only one character.\n",
    "docs = [[token for token in doc if len(token) > 1] for doc in tqdm(docs)]\n",
    "\n",
    "# Remove common words\n",
    "stoplist = set('that for a of the and to in'.split())\n",
    "docs = [[token for token in doc if token not in stoplist] for doc in tqdm(docs)]\n",
    "\n",
    "# Remove words that appear only once\n",
    "frequency = defaultdict(int)\n",
    "for text in docs:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "docs = [\n",
    "    [token for token in text if frequency[token] > 1]\n",
    "    for text in docs\n",
    "]\n",
    "\n",
    "dictionary = corpora.Dictionary(docs)\n",
    "corpus = [dictionary.doc2bow(text) for text in docs]\n",
    "corpora.MmCorpus.serialize(\"../tmp/corpus\", corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import similarities\n",
    "index = similarities.Similarity(\"../tmp/index\",lsi[corpus],num_features=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.save('../tmp/gensim.index')\n",
    "index = similarities.MatrixSimilarity.load('../tmp/gensim.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 483/217801 [01:07<8:22:42,  7.20it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/57/vt366_td3_37y7bqh4rk7nqr0000gn/T/ipykernel_1017/231277170.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvec_lsi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlsi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloaded_corp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvec_lsi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mvec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loaded_corp = corpora.MmCorpus(\"../tmp/corpus\")\n",
    "n = 10\n",
    "vec = np.zeros((217801,2*n))\n",
    "for i in tqdm(range(len(loaded_corp))):\n",
    "    vec_lsi = lsi[loaded_corp[i]]\n",
    "    sims = index[vec_lsi]\n",
    "    sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "    for j in range (n):\n",
    "        vec[i,2*j] = sims[j+1][0]\n",
    "        vec[i,2*j+1] = sims[j+1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(vec)\n",
    "data.to_csv(\"../tmp/similGraph.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cdf7b00ddbd614d21cac29b9426dbd01e82151f124ccbb4ce3c531d165211a8f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('X': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
